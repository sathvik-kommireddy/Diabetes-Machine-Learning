GRADIENT BOOSTING RESULTS

 #DISPLAYING FEATURE IMPORTANCE
> print(xgb.importance(colnames(train.x), model=xgb.class))
               Feature       Gain      Cover  Frequency
                <char>      <num>      <num>      <num>
1:         HbA1c_level 0.37580078 0.12142262 0.12595453
2: blood_glucose_level 0.33755519 0.14924296 0.13362006
3:                 bmi 0.11301585 0.34470656 0.27282834
4:                 age 0.10460790 0.21538173 0.21521987
5:     smoking_history 0.02590142 0.08161498 0.11928377
6:        hypertension 0.01909974 0.02997986 0.03911759
7:       heart_disease 0.01393290 0.02918781 0.04002458
8:              gender 0.01008622 0.02846349 0.05395126
> 
> #COMPUTING PREDICTION ACCURACY FOR TESTING DATA 
> pred.prob<- predict(xgb.class, test.x)
> 
> len<- length(pred.prob)
> pred.diabetes<- c()
> match<- c()
> for (i in 1:len){
+   pred.diabetes[i]<- ifelse(pred.prob[i]>=0.5, 1,0)
+   match[i]<- ifelse(test.y[i]==pred.diabetes[i], 1,0)
+ }
> print(prop<- sum(match)/len)
[1] 0.9680851
> 
> #calculating confusion matrix
> tp <- sum(pred.diabetes == 1 & test.y == 1)
> fp <- sum(pred.diabetes == 1 & test.y == 0)
> tn <- sum(pred.diabetes == 0 & test.y == 0)
> fn <- sum(pred.diabetes == 0 & test.y == 1)
> total <- length(test.y)
> 
> # Metrics
> accuracy <- (tp + tn) / total
> misclassrate <- (fp + fn) / total
> sensitivity <- tp / (tp + fn)
> FNR <- fn / (tp + fn)
> specificity <- tn / (fp + tn)
> FPR <- fp / (fp + tn)
> precision <- tp / (tp + fp)
> NPV <- tn / (fn + tn)
> F1score <- 2 * tp / (2 * tp + fn + fp)
> 
> # Print results
> print("XGBoost Confusion Matrix Results:")
[1] "XGBoost Confusion Matrix Results:"
> print(paste("TP =", tp, " FP =", fp, " TN =", tn, " FN =", fn, "Total =", total))
[1] "TP = 1132  FP = 100  TN = 18069  FN = 533 Total = 19834"
> print(paste("Accuracy =", round(accuracy, 4)))
[1] "Accuracy = 0.9681"
> print(paste("MisclassRate =", round(misclassrate, 4)))
[1] "MisclassRate = 0.0319"
> print(paste("Sensitivity =", round(sensitivity, 4)))
[1] "Sensitivity = 0.6799"
> print(paste("FNR =", round(FNR, 4)))
[1] "FNR = 0.3201"
> print(paste("Specificity =", round(specificity, 4)))
[1] "Specificity = 0.9945"
> print(paste("FPR =", round(FPR, 4)))
[1] "FPR = 0.0055"
> print(paste("Precision =", round(precision, 4)))
[1] "Precision = 0.9188"
> print(paste("NPV =", round(NPV, 4)))
[1] "NPV = 0.9713"
> print(paste("F1 Score =", round(F1score, 4)))
[1] "F1 Score = 0.7815"
> ####ROC CURVE CODE
> 
> #COMPUTING CONFUSION MATRICES AND PERFORMANCE MEASURES FOR TESTING SET
> #FOR A RANGE OF CUT-OFFS
> 
> tpos<- matrix(NA, nrow=nrow(test), ncol=102)
> fpos<- matrix(NA, nrow=nrow(test), ncol=102)
> tneg<- matrix(NA, nrow=nrow(test), ncol=102)
> fneg<- matrix(NA, nrow=nrow(test), ncol=102)
> 
> 
> for (i in 0:101) {
+   tpos[,i+1]<- ifelse(test.y==1 & pred.prob>=0.01*i,1,0)
+   fpos[,i+1]<- ifelse(test.y==0 & pred.prob>=0.01*i, 1,0)
+   tneg[,i+1]<- ifelse(test.y==0 & pred.prob<0.01*i,1,0)
+   fneg[,i+1]<- ifelse(test.y==1 & pred.prob<0.01*i,1,0)
+ }
> 
> tp<- c()
> fp<- c()
> tn<- c()
> fn<- c()
> accuracy<- c()
> misclassrate<- c()
> sensitivity<- c()
> specificity<- c()
> oneminusspec<- c()
> cutoff<- c()
> 
> 
> for (i in 1:102) {
+   tp[i]<- sum(tpos[,i])
+   fp[i]<- sum(fpos[,i])
+   tn[i]<- sum(tneg[,i])
+   fn[i]<- sum(fneg[,i])
+   total<- nrow(test)
+   accuracy[i]<- (tp[i]+tn[i])/total
+   misclassrate[i]<- (fp[i]+fn[i])/total
+   sensitivity[i]<- tp[i]/(tp[i]+fn[i])
+   specificity[i]<- tn[i]/(fp[i]+tn[i])
+   oneminusspec[i]<- fp[i]/(fp[i]+tn[i])
+   cutoff[i]<- 0.01*(i-1)
+ }
> 
> #PLOTTING ROC CURVE
> plot(oneminusspec, sensitivity, type="l", lty=1, main="The Receiver 
+ Operating Characteristic Curve", xlab="1-Specificity", ylab="Sensitivity")
> points(oneminusspec, sensitivity, pch=0) #pch=plot character, 0=square
> 
> #REPORTING MEASURES FOR THE POINT ON ROC CURVE CLOSEST TO THE IDEAL POINT (0,1)
> distance<- c()
> for (i in 1:102)
+   distance[i]<- sqrt(oneminusspec[i]^2+(1-sensitivity[i])^2)
> 
> measures<- cbind(accuracy, misclassrate, sensitivity, specificity, distance, cutoff, tp, fp, tn, fn)
> min.dist<- min(distance)
> print(measures)
         accuracy misclassrate sensitivity specificity  distance cutoff   tp    fp    tn   fn
  [1,] 0.08394676   0.91605324 1.000000000   0.0000000 1.0000000   0.00 1665 18169     0    0
  [2,] 0.80533427   0.19466573 0.975975976   0.7896967 0.2116710   0.01 1625  3821 14348   40
  [3,] 0.83689624   0.16310376 0.957957958   0.8258022 0.1791994   0.02 1595  3165 15004   70
  [4,] 0.85726530   0.14273470 0.939339339   0.8497441 0.1620388   0.03 1564  2730 15439  101
  [5,] 0.87375214   0.12624786 0.920720721   0.8694480 0.1527385   0.04 1533  2372 15797  132
  [6,] 0.88610467   0.11389533 0.909909910   0.8839232 0.1469355   0.05 1515  2109 16060  150
  [7,] 0.89502874   0.10497126 0.893093093   0.8952061 0.1497025   0.06 1487  1904 16265  178
  [8,] 0.90299486   0.09700514 0.883483483   0.9047829 0.1504739   0.07 1471  1730 16439  194
  [9,] 0.91096098   0.08903902 0.872072072   0.9145247 0.1538557   0.08 1452  1553 16616  213
 [10,] 0.91600282   0.08399718 0.861861862   0.9209643 0.1591502   0.09 1435  1436 16733  230
 [11,] 0.92159927   0.07840073 0.851651652   0.9280092 0.1648936   0.10 1418  1308 16861  247
 [12,] 0.92527982   0.07472018 0.839639640   0.9331279 0.1737450   0.11 1398  1215 16954  267
 [13,] 0.93122920   0.06877080 0.829429429   0.9405581 0.1806313   0.12 1381  1080 17089  284
 [14,] 0.93415347   0.06584653 0.818618619   0.9447410 0.1896121   0.13 1363  1004 17165  302
 [15,] 0.93707775   0.06292225 0.812612613   0.9484837 0.1943398   0.14 1353   936 17233  312
 [16,] 0.93985076   0.06014924 0.805405405   0.9521713 0.2003862   0.15 1341   869 17300  324
 [17,] 0.94237168   0.05762832 0.797597598   0.9556387 0.2072068   0.16 1328   806 17363  337
 [18,] 0.94423717   0.05576283 0.789789790   0.9583907 0.2142888   0.17 1315   756 17413  350
 [19,] 0.94701018   0.05298982 0.786786787   0.9616930 0.2166271   0.18 1310   696 17473  355
 [20,] 0.94882525   0.05117475 0.779579580   0.9643349 0.2232872   0.19 1298   648 17521  367
 [21,] 0.95058990   0.04941010 0.772372372   0.9669217 0.2300185   0.20 1286   601 17568  379
 [22,] 0.95225371   0.04774629 0.766966967   0.9692333 0.2350553   0.21 1277   559 17610  388
 [23,] 0.95326208   0.04673792 0.764564565   0.9705542 0.2372697   0.22 1273   535 17634  392
 [24,] 0.95497630   0.04502370 0.760360360   0.9728108 0.2411771   0.23 1266   494 17675  399
 [25,] 0.95583342   0.04416658 0.753753754   0.9743519 0.2475783   0.24 1255   466 17703  410
 [26,] 0.95704346   0.04295654 0.750150150   0.9760031 0.2509996   0.25 1249   436 17733  416
 [27,] 0.95790057   0.04209943 0.745345345   0.9773791 0.2556574   0.26 1241   411 17758  424
 [28,] 0.95921146   0.04078854 0.744144144   0.9789201 0.2567228   0.27 1239   383 17786  426
 [29,] 0.96001815   0.03998185 0.738138138   0.9803511 0.2625980   0.28 1229   357 17812  436
 [30,] 0.96107694   0.03892306 0.735135135   0.9817822 0.2654907   0.29 1224   331 17838  441
 [31,] 0.96168196   0.03831804 0.731531532   0.9827729 0.2690206   0.30 1218   313 17856  447
 [32,] 0.96218615   0.03781385 0.726726727   0.9837636 0.2737552   0.31 1210   295 17874  455
 [33,] 0.96274075   0.03725925 0.724924925   0.9845341 0.2755095   0.32 1207   281 17888  458
 [34,] 0.96319451   0.03680549 0.719519520   0.9855248 0.2808538   0.33 1198   263 17906  467
 [35,] 0.96379954   0.03620046 0.716516517   0.9864605 0.2838066   0.34 1193   246 17923  472
 [36,] 0.96415247   0.03584753 0.713513514   0.9871209 0.2867758   0.35 1188   234 17935  477
 [37,] 0.96445498   0.03554502 0.711111111   0.9876713 0.2891518   0.36 1184   224 17945  481
 [38,] 0.96495916   0.03504084 0.706906907   0.9886070 0.2933144   0.37 1177   207 17962  488
 [39,] 0.96521125   0.03478875 0.703303303   0.9892124 0.2968927   0.38 1171   196 17973  494
 [40,] 0.96576586   0.03423414 0.700900901   0.9900380 0.2992650   0.39 1167   181 17988  498
 [41,] 0.96616920   0.03383080 0.699699700   0.9905884 0.3004477   0.40 1165   171 17998  500
 [42,] 0.96652213   0.03347787 0.699099099   0.9910287 0.3010346   0.41 1164   163 18006  501
 [43,] 0.96667339   0.03332661 0.696096096   0.9914690 0.3040236   0.42 1159   155 18014  506
 [44,] 0.96682464   0.03317536 0.694894895   0.9917442 0.3052168   0.43 1157   150 18019  508
 [45,] 0.96702632   0.03297368 0.692492492   0.9921845 0.3076068   0.44 1153   142 18027  512
 [46,] 0.96712716   0.03287284 0.690690691   0.9924597 0.3094012   0.45 1150   137 18032  515
 [47,] 0.96727841   0.03272159 0.688288288   0.9928450 0.3117938   0.46 1146   130 18039  519
 [48,] 0.96732883   0.03267117 0.685885886   0.9931201 0.3141894   0.47 1142   125 18044  523
 [49,] 0.96758092   0.03241908 0.684084084   0.9935605 0.3159815   0.48 1139   117 18052  526
 [50,] 0.96798427   0.03201573 0.682882883   0.9941108 0.3171718   0.49 1137   107 18062  528
 [51,] 0.96808511   0.03191489 0.679879880   0.9944961 0.3201674   0.50 1132   100 18069  533
 [52,] 0.96823636   0.03176364 0.678078078   0.9948264 0.3219635   0.51 1129    94 18075  536
 [53,] 0.96853887   0.03146113 0.677477477   0.9952116 0.3225581   0.52 1128    87 18082  537
 [54,] 0.96869013   0.03130987 0.676876877   0.9954318 0.3231554   0.53 1127    83 18086  538
 [55,] 0.96894222   0.03105778 0.675675676   0.9958171 0.3243513   0.54 1125    76 18093  540
 [56,] 0.96909348   0.03090652 0.674474474   0.9960922 0.3255490   0.55 1123    71 18098  542
 [57,] 0.96939599   0.03060401 0.673873874   0.9964775 0.3261451   0.56 1122    64 18105  543
 [58,] 0.96939599   0.03060401 0.672672673   0.9965876 0.3273451   0.57 1120    62 18107  545
 [59,] 0.96964808   0.03035192 0.671471471   0.9969729 0.3285425   0.58 1118    55 18114  547
 [60,] 0.96979933   0.03020067 0.670870871   0.9971930 0.3291411   0.59 1117    51 18118  548
 [61,] 0.97000101   0.02999899 0.670870871   0.9974132 0.3291393   0.60 1117    47 18122  548
 [62,] 0.97005143   0.02994857 0.669669670   0.9975783 0.3303392   0.61 1115    44 18125  550
 [63,] 0.97020268   0.02979732 0.669069069   0.9977984 0.3309383   0.62 1114    40 18129  551
 [64,] 0.97000101   0.02999899 0.664864865   0.9979636 0.3351413   0.63 1107    37 18132  558
 [65,] 0.97005143   0.02994857 0.663663664   0.9981287 0.3363415   0.64 1105    34 18135  560
 [66,] 0.97020268   0.02979732 0.663063063   0.9983488 0.3369410   0.65 1104    30 18139  561
 [67,] 0.97025310   0.02974690 0.662462462   0.9984589 0.3375411   0.66 1103    28 18141  562
 [68,] 0.97010185   0.02989815 0.660660661   0.9984589 0.3393428   0.67 1100    28 18141  565
 [69,] 0.97020268   0.02979732 0.660060060   0.9986240 0.3399427   0.68 1099    25 18144  566
 [70,] 0.97030352   0.02969648 0.660060060   0.9987341 0.3399423   0.69 1099    23 18146  566
 [71,] 0.97035394   0.02964606 0.660060060   0.9987891 0.3399421   0.70 1099    22 18147  566
 [72,] 0.97040436   0.02959564 0.660060060   0.9988442 0.3399419   0.71 1099    21 18148  566
 [73,] 0.97035394   0.02964606 0.659459459   0.9988442 0.3405425   0.72 1098    21 18148  567
 [74,] 0.97040436   0.02959564 0.658858859   0.9989543 0.3411427   0.73 1097    19 18150  568
 [75,] 0.97040436   0.02959564 0.658258258   0.9990093 0.3417432   0.74 1096    18 18151  569
 [76,] 0.97050519   0.02949481 0.657657658   0.9991744 0.3423433   0.75 1095    15 18154  570
 [77,] 0.97055561   0.02944439 0.657057057   0.9992845 0.3429437   0.76 1094    13 18156  571
 [78,] 0.97045477   0.02954523 0.655255255   0.9993395 0.3447454   0.77 1091    12 18157  574
 [79,] 0.97045477   0.02954523 0.654654655   0.9993946 0.3453459   0.78 1090    11 18158  575
 [80,] 0.97045477   0.02954523 0.653453453   0.9995047 0.3465469   0.79 1088     9 18160  577
 [81,] 0.97050519   0.02949481 0.653453453   0.9995597 0.3465468   0.80 1088     8 18161  577
 [82,] 0.97050519   0.02949481 0.652852853   0.9996147 0.3471474   0.81 1087     7 18162  578
 [83,] 0.97055561   0.02944439 0.652252252   0.9997248 0.3477479   0.82 1086     5 18164  579
 [84,] 0.97055561   0.02944439 0.651651652   0.9997798 0.3483484   0.83 1085     4 18165  580
 [85,] 0.97055561   0.02944439 0.651651652   0.9997798 0.3483484   0.84 1085     4 18165  580
 [86,] 0.97060603   0.02939397 0.651051051   0.9998899 0.3489490   0.85 1084     2 18167  581
 [87,] 0.97060603   0.02939397 0.651051051   0.9998899 0.3489490   0.86 1084     2 18167  581
 [88,] 0.97065645   0.02934355 0.651051051   0.9999450 0.3489490   0.87 1084     1 18168  581
 [89,] 0.97060603   0.02939397 0.650450450   0.9999450 0.3495496   0.88 1083     1 18168  582
 [90,] 0.97060603   0.02939397 0.650450450   0.9999450 0.3495496   0.89 1083     1 18168  582
 [91,] 0.97060603   0.02939397 0.650450450   0.9999450 0.3495496   0.90 1083     1 18168  582
 [92,] 0.97055561   0.02944439 0.649849850   0.9999450 0.3501502   0.91 1082     1 18168  583
 [93,] 0.97050519   0.02949481 0.649249249   0.9999450 0.3507508   0.92 1081     1 18168  584
 [94,] 0.97050519   0.02949481 0.649249249   0.9999450 0.3507508   0.93 1081     1 18168  584
 [95,] 0.97045477   0.02954523 0.648648649   0.9999450 0.3513514   0.94 1080     1 18168  585
 [96,] 0.97045477   0.02954523 0.648648649   0.9999450 0.3513514   0.95 1080     1 18168  585
 [97,] 0.97045477   0.02954523 0.648648649   0.9999450 0.3513514   0.96 1080     1 18168  585
 [98,] 0.97050519   0.02949481 0.648648649   1.0000000 0.3513514   0.97 1080     0 18169  585
 [99,] 0.97035394   0.02964606 0.646846847   1.0000000 0.3531532   0.98 1077     0 18169  588
[100,] 0.97010185   0.02989815 0.643843844   1.0000000 0.3561562   0.99 1072     0 18169  593
 [ reached 'max' / getOption("max.print") -- omitted 2 rows ]
> 
> #COMPUTING AREA UNDER THE ROC CURVE
> sensitivity<- sensitivity[order(sensitivity)]
> oneminusspec<- oneminusspec[order(oneminusspec)]
> 
> library(Hmisc) #Harrell Miscellaneous packages

Attaching package: ‘Hmisc’

The following objects are masked from ‘package:base’:

    format.pval, units
> lagx<- Lag(oneminusspec,shift=1)
> lagy<- Lag(sensitivity, shift=1)
> lagx[is.na(lagx)]<- 0
> lagy[is.na(lagy)]<- 0
> trapezoid<- (oneminusspec-lagx)*(sensitivity+lagy)/2
> print(AUC<- sum(trapezoid))
[1] 0.9638144