NAIVE BAYES RESULTS

> diabetes.data<- read.csv(file="C:/Users/sathv/OneDrive/Stats Research Project/diabetes_prediction_dataset.csv", 
+ header=TRUE, sep=",")
> 
> diabetes.data$smoking_history<- ifelse(diabetes.data$smoking_history %in% c("current", "former"),1,0)  
> diabetes.data$gender<- ifelse(diabetes.data$gender=='Male',1,0)                                       
> 
> #SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS 
> set.seed(1012312)
> sample <- sample(c(TRUE, FALSE), nrow(diabetes.data), 
+ replace=TRUE, prob=c(0.8,0.2))
> train<- diabetes.data[sample,]
> test<- diabetes.data[!sample,]
> 
> test.x<- data.matrix(test[-9])
> test.y<- data.matrix(test[9])
> 
> #FITTING NAIVE BAYES BINARY CLASSIFIER
> library(e1071)

Attaching package: ‘e1071’

The following object is masked from ‘package:Hmisc’:

    impute
> nb.class<- naiveBayes(as.factor(diabetes) ~ gender + age + hypertension + heart_disease + smoking_history + bmi + HbA1c_level + blood_glucose_level, data=train)
> 
> #COMPUTING PREDICTION ACCURACY FOR TESTING DATA
> pred.y<- as.numeric(predict(nb.class, test.x))-1
> 
> match<- c()
> for (i in 1:length(pred.y))
+   match[i]<- ifelse(test.y[i]==pred.y[i], 1, 0)
> print(paste('accuracy=', round(mean(match)*100, digits=2),'%'))
[1] "accuracy= 90.66 %"
> 
> 
> #calculating confusion matrix
> tp <- sum(pred.y == 1 & test.y == 1)
> fp <- sum(pred.y == 1 & test.y == 0)
> tn <- sum(pred.y == 0 & test.y == 0)
> fn <- sum(pred.y == 0 & test.y == 1)
> total <- length(test.y)
> 
> # Metrics
> accuracy <- (tp + tn) / total
> misclassrate <- (fp + fn) / total
> sensitivity <- tp / (tp + fn)
> FNR <- fn / (tp + fn)
> specificity <- tn / (fp + tn)
> FPR <- fp / (fp + tn)
> precision <- tp / (tp + fp)
> NPV <- tn / (fn + tn)
> F1score <- 2 * tp / (2 * tp + fn + fp)
> 
> # Print results
> print("Naive Bayes Confusion Matrix Results:")
[1] "Naive Bayes Confusion Matrix Results:"
> print(paste("TP =", tp, " FP =", fp, " TN =", tn, " FN =", fn, "Total =", total))
[1] "TP = 1078  FP = 1265  TN = 17116  FN = 610 Total = 20069"
> print(paste("Accuracy =", round(accuracy, 4)))
[1] "Accuracy = 0.9066"
> print(paste("MisclassRate =", round(misclassrate, 4)))
[1] "MisclassRate = 0.0934"
> print(paste("Sensitivity =", round(sensitivity, 4)))
[1] "Sensitivity = 0.6386"
> print(paste("FNR =", round(FNR, 4)))
[1] "FNR = 0.3614"
> print(paste("Specificity =", round(specificity, 4)))
[1] "Specificity = 0.9312"
> print(paste("FPR =", round(FPR, 4)))
[1] "FPR = 0.0688"
> print(paste("Precision =", round(precision, 4)))
[1] "Precision = 0.4601"
> print(paste("NPV =", round(NPV, 4)))
[1] "NPV = 0.9656"
> print(paste("F1 Score =", round(F1score, 4)))
[1] "F1 Score = 0.5349"
> 
> ####ROC CURVE CODE
> 
> #COMPUTING CONFUSION MATRICES AND PERFORMANCE MEASURES FOR TESTING SET
> #FOR A RANGE OF CUT-OFFS
> nb.class<- naiveBayes(as.factor(diabetes) ~ gender + age + hypertension + heart_disease + smoking_history + bmi + HbA1c_level + blood_glucose_level, data=train)
> 
> nb.prob <- predict(nb.class, newdata=test, type = "raw")
> test$prob_1 <- nb.prob[, "1"]
> 
> tpos<- matrix(NA, nrow=nrow(test), ncol=102)
> fpos<- matrix(NA, nrow=nrow(test), ncol=102)
> tneg<- matrix(NA, nrow=nrow(test), ncol=102)
> fneg<- matrix(NA, nrow=nrow(test), ncol=102)
> 
> 
> for (i in 0:101) {
+   tpos[,i+1]<- ifelse(test$diabetes==1 & test$prob_1>=0.01*i,1,0)
+   fpos[,i+1]<- ifelse(test$diabetes==0 & test$prob_1>=0.01*i, 1,0)
+   tneg[,i+1]<- ifelse(test$diabetes==0 & test$prob_1<0.01*i,1,0)
+   fneg[,i+1]<- ifelse(test$diabetes==1 & test$prob_1<0.01*i,1,0)
+ }
> 
> tp<- c()
> fp<- c()
> tn<- c()
> fn<- c()
> accuracy<- c()
> misclassrate<- c()
> sensitivity<- c()
> specificity<- c()
> oneminusspec<- c()
> cutoff<- c()
> 
> 
> for (i in 1:102) {
+   tp[i]<- sum(tpos[,i])
+   fp[i]<- sum(fpos[,i])
+   tn[i]<- sum(tneg[,i])
+   fn[i]<- sum(fneg[,i])
+   total<- nrow(test)
+   accuracy[i]<- (tp[i]+tn[i])/total
+   misclassrate[i]<- (fp[i]+fn[i])/total
+   sensitivity[i]<- tp[i]/(tp[i]+fn[i])
+   specificity[i]<- tn[i]/(fp[i]+tn[i])
+   oneminusspec[i]<- fp[i]/(fp[i]+tn[i])
+   cutoff[i]<- 0.01*(i-1)
+ }
> 
> #PLOTTING ROC CURVE
> plot(oneminusspec, sensitivity, type="l", lty=1, main="The Receiver 
+ Operating Characteristic Curve", xlab="1-Specificity", ylab="Sensitivity")
> points(oneminusspec, sensitivity, pch=0) #pch=plot character, 0=square
> 
> #REPORTING MEASURES FOR THE POINT ON ROC CURVE CLOSEST TO THE IDEAL POINT (0,1)
> distance<- c()
> for (i in 1:102)
+   distance[i]<- sqrt(oneminusspec[i]^2+(1-sensitivity[i])^2)
> 
> measures<- cbind(accuracy, misclassrate, sensitivity, specificity, distance, cutoff, tp, fp, tn, fn)
> min.dist<- min(distance)
> print(measures)
         accuracy misclassrate sensitivity specificity  distance cutoff   tp    fp    tn   fn
  [1,] 0.08410982   0.91589018   1.0000000   0.0000000 1.0000000   0.00 1688 18381     0    0
  [2,] 0.78000897   0.21999103   0.9170616   0.7674229 0.2469228   0.01 1548  4275 14106  140
  [3,] 0.83491953   0.16508047   0.8702607   0.8316740 0.2125228   0.02 1469  3094 15287  219
  [4,] 0.85644526   0.14355474   0.8424171   0.8577335 0.2123020   0.03 1422  2615 15766  266
  [5,] 0.86730779   0.13269221   0.8216825   0.8714977 0.2197953   0.04 1387  2362 16019  301
  [6,] 0.87443321   0.12556679   0.8056872   0.8807464 0.2279888   0.05 1360  2192 16189  328
  [7,] 0.87926653   0.12073347   0.7932464   0.8871661 0.2355388   0.06 1339  2074 16307  349
  [8,] 0.88375106   0.11624894   0.7849526   0.8928241 0.2402750   0.07 1325  1970 16411  363
  [9,] 0.88694006   0.11305994   0.7772512   0.8970132 0.2454044   0.08 1312  1893 16488  376
 [10,] 0.88883352   0.11116648   0.7671801   0.9000054 0.2533851   0.09 1295  1838 16543  393
 [11,] 0.89077682   0.10922318   0.7612559   0.9026712 0.2578209   0.10 1285  1789 16592  403
 [12,] 0.89162390   0.10837610   0.7553318   0.9041401 0.2627768   0.11 1275  1762 16619  413
 [13,] 0.89301908   0.10698092   0.7523697   0.9059355 0.2648942   0.12 1270  1729 16652  418
 [14,] 0.89411530   0.10588470   0.7488152   0.9074588 0.2676896   0.13 1264  1701 16680  424
 [15,] 0.89466341   0.10533659   0.7458531   0.9083293 0.2701744   0.14 1259  1685 16696  429
 [16,] 0.89565997   0.10434003   0.7405213   0.9099070 0.2746742   0.15 1250  1656 16725  438
 [17,] 0.89595894   0.10404106   0.7340047   0.9108318 0.2805431   0.16 1239  1639 16742  449
 [18,] 0.89605860   0.10394140   0.7280806   0.9114847 0.2859635   0.17 1229  1627 16754  459
 [19,] 0.89660671   0.10339329   0.7245261   0.9124096 0.2890640   0.18 1223  1610 16771  465
 [20,] 0.89745378   0.10254622   0.7186019   0.9138785 0.2942819   0.19 1213  1583 16798  475
 [21,] 0.89815138   0.10184862   0.7144550   0.9150209 0.2979218   0.20 1206  1562 16819  482
 [22,] 0.89855000   0.10145000   0.7091232   0.9159458 0.3027778   0.21 1197  1545 16836  491
 [23,] 0.89929742   0.10070258   0.7061611   0.9170339 0.3053271   0.22 1192  1525 16856  496
 [24,] 0.89969605   0.10030395   0.7037915   0.9176867 0.3074329   0.23 1188  1513 16868  500
 [25,] 0.90019433   0.09980567   0.7020142   0.9183940 0.3089580   0.24 1185  1500 16881  503
 [26,] 0.90034381   0.09965619   0.6984597   0.9188836 0.3122602   0.25 1179  1491 16890  509
 [27,] 0.90059295   0.09940705   0.6954976   0.9194277 0.3149819   0.26 1174  1481 16900  514
 [28,] 0.90094175   0.09905825   0.6937204   0.9199717 0.3165624   0.27 1171  1471 16910  517
 [29,] 0.90119089   0.09880911   0.6895735   0.9206246 0.3204139   0.28 1164  1459 16922  524
 [30,] 0.90144003   0.09855997   0.6872038   0.9211142 0.3225902   0.29 1160  1450 16931  528
 [31,] 0.90153969   0.09846031   0.6836493   0.9215494 0.3259329   0.30 1154  1442 16939  534
 [32,] 0.90178883   0.09821117   0.6806872   0.9220935 0.3286793   0.31 1149  1432 16949  539
 [33,] 0.90163934   0.09836066   0.6771327   0.9222567 0.3320953   0.32 1143  1429 16952  545
 [34,] 0.90193831   0.09806169   0.6747630   0.9228007 0.3342736   0.33 1139  1419 16962  549
 [35,] 0.90213763   0.09786237   0.6718009   0.9232904 0.3370445   0.34 1134  1410 16971  554
 [36,] 0.90243659   0.09756341   0.6688389   0.9238888 0.3397950   0.35 1129  1399 16982  559
 [37,] 0.90278539   0.09721461   0.6658768   0.9245416 0.3425380   0.36 1124  1387 16994  564
 [38,] 0.90333350   0.09666650   0.6640995   0.9253033 0.3441057   0.37 1121  1373 17008  567
 [39,] 0.90363247   0.09636753   0.6623223   0.9257929 0.3457354   0.38 1118  1364 17017  570
 [40,] 0.90398126   0.09601874   0.6611374   0.9262826 0.3467883   0.39 1116  1355 17026  572
 [41,] 0.90393144   0.09606856   0.6569905   0.9266090 0.3507731   0.40 1109  1349 17032  579
 [42,] 0.90393144   0.09606856   0.6528436   0.9269898 0.3547507   0.41 1102  1342 17039  586
 [43,] 0.90418058   0.09581942   0.6516588   0.9273707 0.3558323   0.42 1100  1335 17046  588
 [44,] 0.90437989   0.09562011   0.6504739   0.9276971 0.3569260   0.43 1098  1329 17052  590
 [45,] 0.90477851   0.09522149   0.6451422   0.9286219 0.3619653   0.44 1089  1312 17069  599
 [46,] 0.90512731   0.09487269   0.6445498   0.9290572 0.3624607   0.45 1088  1304 17077  600
 [47,] 0.90542628   0.09457372   0.6421801   0.9296012 0.3646794   0.46 1084  1294 17087  604
 [48,] 0.90577508   0.09422492   0.6415877   0.9300365 0.3651771   0.47 1083  1286 17095  605
 [49,] 0.90607404   0.09392596   0.6404028   0.9304717 0.3662572   0.48 1081  1278 17103  607
 [50,] 0.90637301   0.09362699   0.6398104   0.9308525 0.3667668   0.49 1080  1271 17110  608
 [51,] 0.90657233   0.09342767   0.6386256   0.9311789 0.3678693   0.50 1078  1265 17116  610
 [52,] 0.90677164   0.09322836   0.6356635   0.9316686 0.3706889   0.51 1073  1256 17125  615
 [53,] 0.90667198   0.09332802   0.6327014   0.9318318 0.3735708   0.52 1068  1253 17128  620
 [54,] 0.90717026   0.09282974   0.6321090   0.9324302 0.3740447   0.53 1067  1242 17139  621
 [55,] 0.90712043   0.09287957   0.6285545   0.9327022 0.3774927   0.54 1061  1237 17144  627
 [56,] 0.90731975   0.09268025   0.6285545   0.9329199 0.3774540   0.55 1061  1233 17148  627
 [57,] 0.90771837   0.09228163   0.6279621   0.9334095 0.3779504   0.56 1060  1224 17157  628
 [58,] 0.90786786   0.09213214   0.6255924   0.9337903 0.3802167   0.57 1056  1217 17164  632
 [59,] 0.90796751   0.09203249   0.6208531   0.9343344 0.3847913   0.58 1048  1207 17174  640
 [60,] 0.90801734   0.09198266   0.6196682   0.9344976 0.3859311   0.59 1046  1204 17177  642
 [61,] 0.90816682   0.09183318   0.6172986   0.9348784 0.3882025   0.60 1042  1197 17184  646
 [62,] 0.90851562   0.09148438   0.6155213   0.9354224 0.3898642   0.61 1039  1187 17194  649
 [63,] 0.90906373   0.09093627   0.6149289   0.9360753 0.3903410   0.62 1038  1175 17206  650
 [64,] 0.90901390   0.09098610   0.6131517   0.9361841 0.3920767   0.63 1035  1173 17208  653
 [65,] 0.90941253   0.09058747   0.6090047   0.9370002 0.3960382   0.64 1028  1158 17223  660
 [66,] 0.91006029   0.08993971   0.6084123   0.9377618 0.3965028   0.65 1027  1144 17237  661
 [67,] 0.91050874   0.08949126   0.6066351   0.9384147 0.3981567   0.66 1024  1132 17249  664
 [68,] 0.91060840   0.08939160   0.6054502   0.9386323 0.3992938   0.67 1022  1128 17253  666
 [69,] 0.91080771   0.08919229   0.6030806   0.9390675 0.4015692   0.68 1018  1120 17261  670
 [70,] 0.91095720   0.08904280   0.6018957   0.9393395 0.4026993   0.69 1016  1115 17266  672
 [71,] 0.91105685   0.08894315   0.5983412   0.9397748 0.4061488   0.70 1010  1107 17274  678
 [72,] 0.91140565   0.08859435   0.5947867   0.9404820 0.4095610   0.71 1004  1094 17287  684
 [73,] 0.91130599   0.08869401   0.5906398   0.9407540 0.4136253   0.72  997  1089 17292  691
 [74,] 0.91180428   0.08819572   0.5888626   0.9414613 0.4152840   0.73  994  1076 17305  694
 [75,] 0.91180428   0.08819572   0.5835308   0.9419509 0.4204953   0.74  985  1067 17314  703
 [76,] 0.91205342   0.08794658   0.5793839   0.9426038 0.4245141   0.75  978  1055 17326  710
 [77,] 0.91230256   0.08769744   0.5776066   0.9430390 0.4262167   0.76  975  1047 17334  713
 [78,] 0.91270118   0.08729882   0.5752370   0.9436919 0.4284790   0.77  971  1035 17346  717
 [79,] 0.91290049   0.08709951   0.5716825   0.9442359 0.4319323   0.78  965  1025 17356  723
 [80,] 0.91329912   0.08670088   0.5699052   0.9448343 0.4336182   0.79  962  1014 17367  726
 [81,] 0.91344860   0.08655140   0.5663507   0.9453240 0.4370826   0.80  956  1005 17376  732
 [82,] 0.91374757   0.08625243   0.5639810   0.9458680 0.4393664   0.81  952   995 17386  736
 [83,] 0.91424585   0.08575415   0.5616114   0.9466297 0.4416254   0.82  948   981 17400  740
 [84,] 0.91459465   0.08540535   0.5592417   0.9472281 0.4439062   0.83  944   970 17411  744
 [85,] 0.91509293   0.08490707   0.5568720   0.9479898 0.4461698   0.84  940   956 17425  748
 [86,] 0.91618915   0.08381085   0.5527251   0.9495675 0.4501092   0.85  933   927 17454  755
 [87,] 0.91693657   0.08306343   0.5491706   0.9507100 0.4535159   0.86  927   906 17475  761
 [88,] 0.91758433   0.08241567   0.5444313   0.9518525 0.4581059   0.87  919   885 17496  769
 [89,] 0.91838158   0.08161842   0.5390995   0.9532126 0.4632692   0.88  910   860 17521  778
 [90,] 0.91892969   0.08107031   0.5349526   0.9541918 0.4672980   0.89  903   842 17539  785
 [91,] 0.91932832   0.08067168   0.5308057   0.9550079 0.4713466   0.90  896   827 17554  792
 [92,] 0.92002591   0.07997409   0.5254739   0.9562592 0.4765378   0.91  887   804 17577  801
 [93,] 0.92042454   0.07957546   0.5177725   0.9574017 0.4841053   0.92  874   783 17598  814
 [94,] 0.92052419   0.07947581   0.5071090   0.9584897 0.4946359   0.93  856   763 17618  832
 [95,] 0.92072350   0.07927650   0.4976303   0.9595778 0.5039933   0.94  840   743 17638  848
 [96,] 0.92112213   0.07887787   0.4851896   0.9611555 0.5162738   0.95  819   714 17667  869
 [97,] 0.92117196   0.07882804   0.4680095   0.9627877 0.5332904   0.96  790   684 17697  898
 [98,] 0.92167024   0.07832976   0.4561611   0.9644198 0.5450015   0.97  770   654 17727  918
 [99,] 0.92152075   0.07847925   0.4336493   0.9663239 0.5673510   0.98  732   619 17762  956
[100,] 0.92157058   0.07842942   0.4081754   0.9687177 0.5926508   0.99  689   575 17806  999
 [ reached 'max' / getOption("max.print") -- omitted 2 rows ]
> 
> #COMPUTING AREA UNDER THE ROC CURVE
> sensitivity<- sensitivity[order(sensitivity)]
> oneminusspec<- oneminusspec[order(oneminusspec)]
> 
> library(Hmisc) #Harrell Miscellaneous packages
> lagx<- Lag(oneminusspec,shift=1)
> lagy<- Lag(sensitivity, shift=1)
> lagx[is.na(lagx)]<- 0
> lagy[is.na(lagy)]<- 0
> trapezoid<- (oneminusspec-lagx)*(sensitivity+lagy)/2
> print(AUC<- sum(trapezoid))
[1] 0.898346