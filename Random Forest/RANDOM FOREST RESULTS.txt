 diabetes.data<- read.csv(file="C:/Users/sathv/OneDrive/Stats Research Project/diabetes_prediction_dataset.csv", 
+ header=TRUE, sep=",")
> 
> #SPLITTING DATA INTO SUBSETS
> class0 <- subset(diabetes.data, diabetes == 0)
> class1 <- subset(diabetes.data, diabetes == 1)
> 
> #CALCULATING HOW MANY 0'S NEEDED FOR ALL 1'S TO MAKE A GIVEN RATIO
> n1 <- nrow(class1)
> n0_needed <- 10*nrow(class1)
> 
> print(n0_needed)
[1] 85000
> 
> #SAMPLING THE 0'S
> set.seed(447558)
> class0_sample <- class0[sample(nrow(class0), size = n0_needed), ]
> 
> print(nrow(class0_sample))
[1] 85000
> print(nrow(class1))
[1] 8500
> print(nrow(class0))
[1] 91500
> #ADDING THE SAMPLE TO THE 1'S
> ratio_data = rbind(class1,class0_sample)
> 
> #SPLITTING DATA INTO 80% TRAINING AND 20% TESTING SETS 
> set.seed(447558)
> 
> n_train0 <- floor(0.8 * nrow(class0_sample))
> train0<- class0_sample[sample(nrow(class0_sample), size = n_train0),]
> test0<- class0_sample[!(rownames(class0_sample) %in% rownames(train0)),]
> 
> n_train1 <- floor(0.8 * nrow(class1))
> train1<- class1[sample(nrow(class1), size = n_train1),]
> test1<- class1[!(rownames(class1) %in% rownames(train1)),]
> 
> train <- rbind(train0, train1)
> test <- rbind(test1, test0)
> #BUILDING RANDOM FOREST BINARY CLASSIFIER
> library(randomForest)
randomForest 4.7-1.2
Type rfNews() to see new features/changes/bug fixes.

Attaching package: ‘randomForest’

The following object is masked from ‘package:ggplot2’:

    margin
> rf.class<- randomForest(as.factor(diabetes) ~ gender + age + hypertension	+ heart_disease + bmi + HbA1c_level + blood_glucose_level + smoking_history,
+ data=train, ntree=300, mtry=5, maxnodes=30)
> 
> #DISPLAYING FEATURE IMPORTANCE
> print(importance(rf.class,type=2)) 
                    MeanDecreaseGini
gender                      1.166925
age                       264.553636
hypertension               60.838456
heart_disease              35.852234
bmi                       129.375440
HbA1c_level              4956.566144
blood_glucose_level      3208.050564
smoking_history             6.284931
> 
> #COMPUTING PREDICTION ACCURACY FOR TESTING DATA 
> predclass<- predict(rf.class, newdata=test)
> test<- cbind(test,predclass)
> 
> accuracy<- c()
> n<- nrow(test)
> for (i in 1:n)
+   accuracy[i]<- ifelse(test$diabetes[i]==test$predclass[i],1,0)
> 
> print(accuracy<- mean(accuracy))
[1] 0.9702674
> 
> #calculating confusion matrix
> tp <- sum(predclass == 1 & test$diabetes == 1)
> fp <- sum(predclass == 1 & test$diabetes == 0)
> tn <- sum(predclass == 0 & test$diabetes == 0)
> fn <- sum(predclass == 0 & test$diabetes == 1)
> total <- length(test$diabetes)
> 
> # Metrics
> accuracy <- (tp + tn) / total
> misclassrate <- (fp + fn) / total
> sensitivity <- tp / (tp + fn)
> FNR <- fn / (tp + fn)
> specificity <- tn / (fp + tn)
> FPR <- fp / (fp + tn)
> precision <- tp / (tp + fp)
> NPV <- tn / (fn + tn)
> F1score <- 2 * tp / (2 * tp + fn + fp)
> 
> # Print results
> print("Random Forest Confusion Matrix Results:")
[1] "Random Forest Confusion Matrix Results:"
> print(paste("TP =", tp, " FP =", fp, " TN =", tn, " FN =", fn, "Total =", total))
[1] "TP = 1144  FP = 0  TN = 17000  FN = 556 Total = 18700"
> print(paste("Accuracy =", round(accuracy, 4)))
[1] "Accuracy = 0.9703"
> print(paste("MisclassRate =", round(misclassrate, 4)))
[1] "MisclassRate = 0.0297"
> print(paste("Sensitivity =", round(sensitivity, 4)))
[1] "Sensitivity = 0.6729"
> print(paste("FNR =", round(FNR, 4)))
[1] "FNR = 0.3271"
> print(paste("Specificity =", round(specificity, 4)))
[1] "Specificity = 1"
> print(paste("FPR =", round(FPR, 4)))
[1] "FPR = 0"
> print(paste("Precision =", round(precision, 4)))
[1] "Precision = 1"
> print(paste("NPV =", round(NPV, 4)))
[1] "NPV = 0.9683"
> print(paste("F1 Score =", round(F1score, 4)))
[1] "F1 Score = 0.8045"
> 
> ####ROC CURVE CODE
> 
> #COMPUTING CONFUSION MATRICES AND PERFORMANCE MEASURES FOR TESTING SET
> #FOR A RANGE OF CUT-OFFS
> prob_rf <- predict(rf.class, newdata=test, type="prob")
> test$prob_1 <- prob_rf[, "1"]
> 
> tpos<- matrix(NA, nrow=nrow(test), ncol=102)
> fpos<- matrix(NA, nrow=nrow(test), ncol=102)
> tneg<- matrix(NA, nrow=nrow(test), ncol=102)
> fneg<- matrix(NA, nrow=nrow(test), ncol=102)
> 
> 
> for (i in 0:101) {
+   tpos[,i+1]<- ifelse(test$diabetes==1 & test$prob_1>=0.01*i,1,0)
+   fpos[,i+1]<- ifelse(test$diabetes==0 & test$prob_1>=0.01*i, 1,0)
+   tneg[,i+1]<- ifelse(test$diabetes==0 & test$prob_1<0.01*i,1,0)
+   fneg[,i+1]<- ifelse(test$diabetes==1 & test$prob_1<0.01*i,1,0)
+ }
> 
> tp<- c()
> fp<- c()
> tn<- c()
> fn<- c()
> accuracy<- c()
> misclassrate<- c()
> sensitivity<- c()
> specificity<- c()
> oneminusspec<- c()
> cutoff<- c()
> 
> 
> for (i in 1:102) {
+   tp[i]<- sum(tpos[,i])
+   fp[i]<- sum(fpos[,i])
+   tn[i]<- sum(tneg[,i])
+   fn[i]<- sum(fneg[,i])
+   total<- nrow(test)
+   accuracy[i]<- (tp[i]+tn[i])/total
+   misclassrate[i]<- (fp[i]+fn[i])/total
+   sensitivity[i]<- tp[i]/(tp[i]+fn[i])
+   specificity[i]<- tn[i]/(fp[i]+tn[i])
+   oneminusspec[i]<- fp[i]/(fp[i]+tn[i])
+   cutoff[i]<- 0.01*(i-1)
+ }
> 
> #PLOTTING ROC CURVE
> plot(oneminusspec, sensitivity, type="l", lty=1, main="The Receiver 
+ Operating Characteristic Curve", xlab="1-Specificity", ylab="Sensitivity")
> points(oneminusspec, sensitivity, pch=0) #pch=plot character, 0=square
> 
> #REPORTING MEASURES FOR THE POINT ON ROC CURVE CLOSEST TO THE IDEAL POINT (0,1)
> distance<- c()
> for (i in 1:102)
+   distance[i]<- sqrt(oneminusspec[i]^2+(1-sensitivity[i])^2)
> 
> measures<- cbind(accuracy, misclassrate, sensitivity, specificity, distance, cutoff, tp, fp, tn, fn)
> min.dist<- min(distance)
> print(measures)
         accuracy misclassrate sensitivity specificity  distance cutoff   tp    fp
  [1,] 0.09090909   0.90909091   1.0000000   0.0000000 1.0000000   0.00 1700 17000
  [2,] 0.96620321   0.03379679   0.7317647   0.9896471 0.2684350   0.01 1244   176
  [3,] 0.96855615   0.03144385   0.7252941   0.9928824 0.2747981   0.02 1233   121
  [4,] 0.96925134   0.03074866   0.7211765   0.9940588 0.2788868   0.03 1226   101
  [5,] 0.96935829   0.03064171   0.7164706   0.9946471 0.2835799   0.04 1218    91
  [6,] 0.97005348   0.02994652   0.7129412   0.9957647 0.2870901   0.05 1212    72
  [7,] 0.97032086   0.02967914   0.7100000   0.9963529 0.2900229   0.06 1207    62
  [8,] 0.97042781   0.02957219   0.7082353   0.9966471 0.2917840   0.07 1204    57
  [9,] 0.97053476   0.02946524   0.7047059   0.9971176 0.2953082   0.08 1198    49
 [10,] 0.97042781   0.02957219   0.7000000   0.9974706 0.3000107   0.09 1190    43
 [11,] 0.97064171   0.02935829   0.6988235   0.9978235 0.3011843   0.10 1188    37
 [12,] 0.97074866   0.02925134   0.6976471   0.9980588 0.3023592   0.11 1186    33
 [13,] 0.97085561   0.02914439   0.6964706   0.9982941 0.3035342   0.12 1184    29
 [14,] 0.97074866   0.02925134   0.6947059   0.9983529 0.3052986   0.13 1181    28
 [15,] 0.97096257   0.02903743   0.6947059   0.9985882 0.3052974   0.14 1181    24
 [16,] 0.97106952   0.02893048   0.6947059   0.9987059 0.3052969   0.15 1181    22
 [17,] 0.97106952   0.02893048   0.6941176   0.9987647 0.3058848   0.16 1180    21
 [18,] 0.97106952   0.02893048   0.6935294   0.9988235 0.3064728   0.17 1179    20
 [19,] 0.97096257   0.02903743   0.6923529   0.9988235 0.3076493   0.18 1177    20
 [20,] 0.97106952   0.02893048   0.6923529   0.9989412 0.3076489   0.19 1177    18
 [21,] 0.97090909   0.02909091   0.6900000   0.9990000 0.3100016   0.20 1173    17
 [22,] 0.97090909   0.02909091   0.6894118   0.9990588 0.3105897   0.21 1172    16
 [23,] 0.97090909   0.02909091   0.6876471   0.9992353 0.3123539   0.22 1169    13
 [24,] 0.97069519   0.02930481   0.6847059   0.9992941 0.3152949   0.23 1164    12
 [25,] 0.97064171   0.02935829   0.6841176   0.9992941 0.3158831   0.24 1163    12
 [26,] 0.97053476   0.02946524   0.6829412   0.9992941 0.3170596   0.25 1161    12
 [27,] 0.97048128   0.02951872   0.6811765   0.9994118 0.3188241   0.26 1158    10
 [28,] 0.97042781   0.02957219   0.6805882   0.9994118 0.3194123   0.27 1157    10
 [29,] 0.97026738   0.02973262   0.6788235   0.9994118 0.3211770   0.28 1154    10
 [30,] 0.97016043   0.02983957   0.6776471   0.9994118 0.3223535   0.29 1152    10
 [31,] 0.97021390   0.02978610   0.6776471   0.9994706 0.3223534   0.30 1152     9
 [32,] 0.97021390   0.02978610   0.6770588   0.9995294 0.3229415   0.31 1151     8
 [33,] 0.97021390   0.02978610   0.6770588   0.9995294 0.3229415   0.32 1151     8
 [34,] 0.97010695   0.02989305   0.6758824   0.9995294 0.3241180   0.33 1149     8
 [35,] 0.97010695   0.02989305   0.6741176   0.9997059 0.3258825   0.34 1146     5
 [36,] 0.97021390   0.02978610   0.6729412   0.9999412 0.3270588   0.35 1144     1
 [37,] 0.97021390   0.02978610   0.6729412   0.9999412 0.3270588   0.36 1144     1
 [38,] 0.97021390   0.02978610   0.6729412   0.9999412 0.3270588   0.37 1144     1
 [39,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.38 1144     0
 [40,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.39 1144     0
 [41,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.40 1144     0
 [42,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.41 1144     0
 [43,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.42 1144     0
 [44,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.43 1144     0
 [45,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.44 1144     0
 [46,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.45 1144     0
 [47,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.46 1144     0
 [48,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.47 1144     0
 [49,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.48 1144     0
 [50,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.49 1144     0
 [51,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.50 1144     0
 [52,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.51 1144     0
 [53,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.52 1144     0
 [54,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.53 1144     0
 [55,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.54 1144     0
 [56,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.55 1144     0
 [57,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.56 1144     0
 [58,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.57 1144     0
 [59,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.58 1144     0
 [60,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.59 1144     0
 [61,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.60 1144     0
 [62,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.61 1144     0
 [63,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.62 1144     0
 [64,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.63 1144     0
 [65,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.64 1144     0
 [66,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.65 1144     0
 [67,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.66 1144     0
 [68,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.67 1144     0
 [69,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.68 1144     0
 [70,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.69 1144     0
 [71,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.70 1144     0
 [72,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.71 1144     0
 [73,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.72 1144     0
 [74,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.73 1144     0
 [75,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.74 1144     0
 [76,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.75 1144     0
 [77,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.76 1144     0
 [78,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.77 1144     0
 [79,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.78 1144     0
 [80,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.79 1144     0
 [81,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.80 1144     0
 [82,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.81 1144     0
 [83,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.82 1144     0
 [84,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.83 1144     0
 [85,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.84 1144     0
 [86,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.85 1144     0
 [87,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.86 1144     0
 [88,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.87 1144     0
 [89,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.88 1144     0
 [90,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.89 1144     0
 [91,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.90 1144     0
 [92,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.91 1144     0
 [93,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.92 1144     0
 [94,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.93 1144     0
 [95,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.94 1144     0
 [96,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.95 1144     0
 [97,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.96 1144     0
 [98,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.97 1144     0
 [99,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.98 1144     0
[100,] 0.97026738   0.02973262   0.6729412   1.0000000 0.3270588   0.99 1144     0
          tn   fn
  [1,]     0    0
  [2,] 16824  456
  [3,] 16879  467
  [4,] 16899  474
  [5,] 16909  482
  [6,] 16928  488
  [7,] 16938  493
  [8,] 16943  496
  [9,] 16951  502
 [10,] 16957  510
 [11,] 16963  512
 [12,] 16967  514
 [13,] 16971  516
 [14,] 16972  519
 [15,] 16976  519
 [16,] 16978  519
 [17,] 16979  520
 [18,] 16980  521
 [19,] 16980  523
 [20,] 16982  523
 [21,] 16983  527
 [22,] 16984  528
 [23,] 16987  531
 [24,] 16988  536
 [25,] 16988  537
 [26,] 16988  539
 [27,] 16990  542
 [28,] 16990  543
 [29,] 16990  546
 [30,] 16990  548
 [31,] 16991  548
 [32,] 16992  549
 [33,] 16992  549
 [34,] 16992  551
 [35,] 16995  554
 [36,] 16999  556
 [37,] 16999  556
 [38,] 16999  556
 [39,] 17000  556
 [40,] 17000  556
 [41,] 17000  556
 [42,] 17000  556
 [43,] 17000  556
 [44,] 17000  556
 [45,] 17000  556
 [46,] 17000  556
 [47,] 17000  556
 [48,] 17000  556
 [49,] 17000  556
 [50,] 17000  556
 [51,] 17000  556
 [52,] 17000  556
 [53,] 17000  556
 [54,] 17000  556
 [55,] 17000  556
 [56,] 17000  556
 [57,] 17000  556
 [58,] 17000  556
 [59,] 17000  556
 [60,] 17000  556
 [61,] 17000  556
 [62,] 17000  556
 [63,] 17000  556
 [64,] 17000  556
 [65,] 17000  556
 [66,] 17000  556
 [67,] 17000  556
 [68,] 17000  556
 [69,] 17000  556
 [70,] 17000  556
 [71,] 17000  556
 [72,] 17000  556
 [73,] 17000  556
 [74,] 17000  556
 [75,] 17000  556
 [76,] 17000  556
 [77,] 17000  556
 [78,] 17000  556
 [79,] 17000  556
 [80,] 17000  556
 [81,] 17000  556
 [82,] 17000  556
 [83,] 17000  556
 [84,] 17000  556
 [85,] 17000  556
 [86,] 17000  556
 [87,] 17000  556
 [88,] 17000  556
 [89,] 17000  556
 [90,] 17000  556
 [91,] 17000  556
 [92,] 17000  556
 [93,] 17000  556
 [94,] 17000  556
 [95,] 17000  556
 [96,] 17000  556
 [97,] 17000  556
 [98,] 17000  556
 [99,] 17000  556
[100,] 17000  556
 [ reached 'max' / getOption("max.print") -- omitted 2 rows ]
> 
> #COMPUTING AREA UNDER THE ROC CURVE
> sensitivity<- sensitivity[order(sensitivity)]
> oneminusspec<- oneminusspec[order(oneminusspec)]
> 
> library(Hmisc) #Harrell Miscellaneous packages

Attaching package: ‘Hmisc’

The following objects are masked from ‘package:base’:

    format.pval, units
> lagx<- Lag(oneminusspec,shift=1)
> lagy<- Lag(sensitivity, shift=1)
> lagx[is.na(lagx)]<- 0
> lagy[is.na(lagy)]<- 0
> trapezoid<- (oneminusspec-lagx)*(sensitivity+lagy)/2
> print(AUC<- sum(trapezoid))
[1] 0.8642994